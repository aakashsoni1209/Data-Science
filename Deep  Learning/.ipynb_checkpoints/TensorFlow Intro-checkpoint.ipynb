{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defind the observations\n",
    "observations = 1000\n",
    "#get the random value so we can find the input variable in each time\n",
    "xs = np.random.uniform(low=-10,high=10,size=(observations,1))\n",
    "zs = np.random.uniform(low=-10,high=10,size=(observations,1))\n",
    "#the column stack function will `make the input as matrics\n",
    "generated_inputs = np.column_stack(tup=(xs,zs))\n",
    "\n",
    "#every target contains noise in the data.\n",
    "noise = np.random.uniform(-1,1,(observations,1))\n",
    "#define the target, as it is the value that we define for the algorithm to predict/to get\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "np.savez('TF_intro',inputs=generated_inputs,targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Install Software\\Anaconda For Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None,input_size])\n",
    "targets = tf.placeholder(tf.float32, [None,output_size])\n",
    "\n",
    "weights = tf.Variable(tf.random_uniform([input_size,output_size],minval=-0.1,maxval=0.1))\n",
    "baises = tf.Variable(tf.random_uniform([output_size],minval=-0.1,maxval=0.1))\n",
    "#using basic equation y = wx + b\n",
    "outputs = tf.matmul(inputs,weights) + baises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function and Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Install Software\\Anaconda For Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:448: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#we are using L2-norm function but there are other function out there like huber loss \n",
    "#losses = tf.losses.mean_squared_error(labels=targets, predictions=outputs)/ 2.\n",
    "losses = tf.losses.huber_loss(labels=targets, predictions=outputs)/ 2.\n",
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(initialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.434033\n",
      "8.171893\n",
      "7.9106193\n",
      "7.650291\n",
      "7.3909793\n",
      "7.132833\n",
      "6.875983\n",
      "6.62036\n",
      "6.366022\n",
      "6.113259\n",
      "5.8624287\n",
      "5.6139874\n",
      "5.368359\n",
      "5.125914\n",
      "4.8868856\n",
      "4.651618\n",
      "4.420653\n",
      "4.194705\n",
      "3.9745743\n",
      "3.7609434\n",
      "3.554499\n",
      "3.356306\n",
      "3.1674821\n",
      "2.9896758\n",
      "2.8247807\n",
      "2.6767993\n",
      "2.5474253\n",
      "2.4374614\n",
      "2.3472214\n",
      "2.274959\n",
      "2.2173128\n",
      "2.171997\n",
      "2.1362176\n",
      "2.1077335\n",
      "2.084623\n",
      "2.0650897\n",
      "2.0478861\n",
      "2.0321858\n",
      "2.017475\n",
      "2.003438\n",
      "1.9898589\n",
      "1.9765838\n",
      "1.9635125\n",
      "1.950582\n",
      "1.9377549\n",
      "1.9250062\n",
      "1.9123178\n",
      "1.899674\n",
      "1.8870633\n",
      "1.8744777\n",
      "1.8619121\n",
      "1.8493631\n",
      "1.8368262\n",
      "1.8242986\n",
      "1.8117785\n",
      "1.7992651\n",
      "1.7867571\n",
      "1.7742536\n",
      "1.7617544\n",
      "1.7492588\n",
      "1.7367666\n",
      "1.7242776\n",
      "1.7117916\n",
      "1.6993084\n",
      "1.6868281\n",
      "1.6743504\n",
      "1.661875\n",
      "1.6494021\n",
      "1.6369324\n",
      "1.6244651\n",
      "1.612001\n",
      "1.5995402\n",
      "1.5870835\n",
      "1.5746294\n",
      "1.5621792\n",
      "1.5497324\n",
      "1.5372889\n",
      "1.5248486\n",
      "1.5124118\n",
      "1.4999778\n",
      "1.4875472\n",
      "1.4751191\n",
      "1.4626943\n",
      "1.4502729\n",
      "1.4378548\n",
      "1.4254397\n",
      "1.413027\n",
      "1.4006172\n",
      "1.3882102\n",
      "1.3758059\n",
      "1.3634044\n",
      "1.3510057\n",
      "1.3386091\n",
      "1.3262154\n",
      "1.3138235\n",
      "1.3014348\n",
      "1.2890494\n",
      "1.2766668\n",
      "1.264287\n",
      "1.25191\n"
     ]
    }
   ],
   "source": [
    "#epoch is the iteration of learning\n",
    "for e in range(100):\n",
    "    \n",
    "    _,curr_loss = sess.run([optimize,losses],feed_dict={inputs: data['inputs'],targets: data['targets']})\n",
    "    \n",
    "    print(curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
