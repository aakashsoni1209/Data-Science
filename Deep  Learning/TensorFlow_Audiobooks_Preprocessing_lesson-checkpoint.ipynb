{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data. Balance the dataset. Create 3 datasets: training, validation, and test. Save the newly created sets in a tensor friendly format (e.g. *.npz)\n",
    "\n",
    "Since we are dealing with real life data, we will need to preprocess it a bit. This is the relevant code, which is not that hard, but is crucial to creating a good model.\n",
    "\n",
    "If you want to know how to do that, go through the code. In any case, this should do the trick for most datasets organized in the way: many inputs, and then 1 cell containing the targets (supervised learning datasets). Keep in mind that a specific problem may require additional preprocessing.\n",
    "\n",
    "Note that we have removed the header row, which contains the names of the categories. We simply want the data.\n",
    "\n",
    "This code does not include comments - it is the same as the one in the lesson. Please refer to the other file if you want the code with comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "raw_csv_data = np.loadtxt('1.1 Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14084\n",
      "[0. 0. 0. ... 0. 0. 1.]\n",
      "[[1620.   1620.     19.73 ... 1603.8     5.     92.  ]\n",
      " [2160.   2160.      5.33 ...    0.      0.      0.  ]\n",
      " [2160.   2160.      5.33 ...    0.      0.    388.  ]\n",
      " ...\n",
      " [2160.   2160.      5.33 ...    0.      0.      6.  ]\n",
      " [1674.   3348.      7.99 ...    0.      0.      0.  ]\n",
      " [1674.   3348.      5.33 ...    0.      0.      0.  ]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "print(targets_all.shape[0])\n",
    "print(targets_all)\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] ==0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "print(unscaled_inputs_equal_priors)\n",
    "targets_equal_priors = np.delete (targets_all, indices_to_remove, axis=0)\n",
    "print(targets_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21053387 -0.18888517  1.97823887 ...  4.80955413 11.83828419\n",
      "   0.09415043]\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "   2.979214  ]\n",
      " ...\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.7440775 ]\n",
      " [ 0.31737498  1.7482432   0.04679395 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]\n",
      " [ 0.31737498  1.7482432  -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]]\n"
     ]
    }
   ],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)\n",
    "print(scaled_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 4471 4472 4473]\n",
      "[[-0.64419501 -0.67316726 -0.26579083 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]\n",
      " [ 1.27894497  0.41646744 -0.39082475 ...  5.91794121 -0.20183481\n",
      "   1.1565556 ]\n",
      " [-0.64419501 -0.67316726 -0.26579083 ... -0.41569922 -0.20183481\n",
      "   1.1565556 ]\n",
      " ...\n",
      " [ 0.21053387 -0.18888517  0.39886313 ...  2.27609796  2.20618899\n",
      "  -0.68559648]\n",
      " [-0.64419501 -0.67316726 -0.39082475 ...  2.17757466 -0.20183481\n",
      "   0.87389734]\n",
      " [-2.35365278 -1.64173144 -0.39082475 ...  0.63990752 -0.20183481\n",
      "  -0.80255852]]\n",
      "[1. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "print(shuffled_indices)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]\n",
    "print(shuffled_inputs)\n",
    "print(shuffled_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4474\n",
      "1793.0 3579 0.5009779267951942\n",
      "230.0 447 0.5145413870246085\n",
      "214.0 448 0.47767857142857145\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "print(samples_count)\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
